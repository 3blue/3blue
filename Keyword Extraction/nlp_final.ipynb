{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"nlp_final.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"trusted":true,"id":"3JJR9Oeem6_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606967247828,"user_tz":360,"elapsed":9152,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"308bc26b-d4d8-4030-f968-b2195c08f2db"},"source":["#Installing pke\n","\n","!pip install git+https://github.com/boudinfl/pke.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/boudinfl/pke.git\n","  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-x3ocfnbz\n","  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-x3ocfnbz\n","Requirement already satisfied (use --upgrade to upgrade): pke==1.8.1 from git+https://github.com/boudinfl/pke.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (3.2.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.4.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.2.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.15.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.0)\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.17.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pke==1.8.1) (4.4.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (3.0.4)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.4)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.0.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.8.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.4)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (4.41.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (50.3.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (2.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.4.0)\n","Building wheels for collected packages: pke\n","  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pke: filename=pke-1.8.1-cp36-none-any.whl size=8763600 sha256=3c847c9961d82d83529500f270815a24a82742e98bd8daf7fe6188a7bc10309b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8uzgfu9l/wheels/8d/24/54/6582e854e9e32dd6c632af6762b3a5d2f6b181c2992e165462\n","Successfully built pke\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6YYp92BBMYC","executionInfo":{"status":"ok","timestamp":1606967247999,"user_tz":360,"elapsed":9287,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"39e4ac19-92b0-4346-8540-bb44396f8558"},"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"aa88L1N1m6_y"},"source":["import numpy as np \n","import pandas as pd \n","import os\n","import nltk\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n","import re\n","import pke"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XcLAwkzBZst","executionInfo":{"status":"ok","timestamp":1606967248001,"user_tz":360,"elapsed":9278,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"a6746d1a-4b18-4d38-e5d9-a2bd9a7743d3"},"source":["import os\n","from google.colab import drive \n","drive.mount('/content/drive')\n","os.chdir('/content/drive/My Drive/NLP/Final')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"oUnbEMssm6_y"},"source":["papers = pd.read_csv('201812_CL_Github.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"vOm6Vxs8m6_y","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1606967248004,"user_tz":360,"elapsed":9268,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"bbe39527-7757-44a1-ee1c-f9bfa41226e0"},"source":["papers.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Abstract</th>\n","      <th>Arxiv Link</th>\n","      <th>Github Link</th>\n","      <th>ID</th>\n","      <th>Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Discourse structures are beneficial for vari...</td>\n","      <td>http://arxiv.org/abs/1812.00176</td>\n","      <td>github.com/irit-melodi/irit-stac</td>\n","      <td>1812.00176</td>\n","      <td>A Deep Sequential Model for Discourse Parsing ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Learning good representations is of crucial ...</td>\n","      <td>http://arxiv.org/abs/1812.00271</td>\n","      <td>github.com/mravanelli/SincNet/</td>\n","      <td>1812.00271</td>\n","      <td>Learning Speaker Representations with Mutual I...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The explosive growth in fake news and its er...</td>\n","      <td>http://arxiv.org/abs/1812.00315</td>\n","      <td>github.com/borisveytsman/acmart/issues/138</td>\n","      <td>1812.00315</td>\n","      <td>Fake News: A Survey of Research, Detection Met...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The amount of dialogue history to include in...</td>\n","      <td>http://arxiv.org/abs/1812.00350</td>\n","      <td>github.com/keras-team/keras</td>\n","      <td>1812.00350</td>\n","      <td>A Study on Dialogue Reward Prediction for Open...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Detecting controversy in general web pages i...</td>\n","      <td>http://arxiv.org/abs/1812.00382</td>\n","      <td>github.com/aboSamoor/polyglot</td>\n","      <td>1812.00382</td>\n","      <td>Improved and Robust Controversy Detection in G...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Abstract  ...                                              Title\n","0    Discourse structures are beneficial for vari...  ...  A Deep Sequential Model for Discourse Parsing ...\n","1    Learning good representations is of crucial ...  ...  Learning Speaker Representations with Mutual I...\n","2    The explosive growth in fake news and its er...  ...  Fake News: A Survey of Research, Detection Met...\n","3    The amount of dialogue history to include in...  ...  A Study on Dialogue Reward Prediction for Open...\n","4    Detecting controversy in general web pages i...  ...  Improved and Robust Controversy Detection in G...\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"trusted":true,"id":"f54upMJim6_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606967248005,"user_tz":360,"elapsed":9259,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"52c30bef-0285-4949-a72d-e170171a5cd8"},"source":["papers.shape\n","#Total 106 papers given"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(106, 5)"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"gnWvwsY12G3H","executionInfo":{"status":"ok","timestamp":1606967248149,"user_tz":360,"elapsed":9393,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"b27f800b-924f-42a0-ccf7-893a4b8fd8f2"},"source":["ex = papers[\"Abstract\"].iloc[3].replace(\"\\n\", \" \")\n","ex"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'  The amount of dialogue history to include in a conversational agent is often underestimated and/or set in an empirical and thus possibly naive way. This suggests that principled investigations into optimal context windows are urgently needed given that the amount of dialogue history and corresponding representations can play an important role in the overall performance of a conversational system. This paper studies the amount of history required by conversational agents for reliably predicting dialogue rewards. The task of dialogue reward prediction is chosen for investigating the effects of varying amounts of dialogue history and their impact on system performance. Experimental results using a dataset of 18K human-human dialogues report that lengthy dialogue histories of at least 10 sentences are preferred (25 sentences being the best in our experiments) over short ones, and that lengthy histories are useful for training dialogue reward predictors with strong positive correlations between target dialogue rewards and predicted ones. '"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"j5K4KvmXm6_y"},"source":["#### Keyphrase Extraction"]},{"cell_type":"code","metadata":{"trusted":true,"id":"fj0-sAwom6_y"},"source":["#TextRank code credit: https://www.kaggle.com/mohitr/keyphrase-extraction-from-research-papers\n","\n","def extract_keyphrases(caption, n):\n","    extractor = pke.unsupervised.TextRank() \n","    extractor.load_document(caption)\n","    extractor.candidate_selection()\n","    extractor.candidate_weighting()\n","    keyphrases = extractor.get_n_best(n=n, stemming=False)\n","    #print(keyphrases,\"\\n\")\n","    return(keyphrases)\n","    \n","papers['Textrank_Keyphrases'] = papers.apply(lambda row: (extract_keyphrases(row['Abstract'],5)),axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYIskNH1K30I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606967307405,"user_tz":360,"elapsed":68639,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"34ab5007-63aa-4ee3-8d60-733b4f113b09"},"source":["punc = '''!()[]{};:'\"\\,<>.?@#$^&*_~`…”“'''\n","corpus = []\n","corpus_raw = [a.replace(\"\\n\", \" \") for a in papers[\"Abstract\"]]\n","for a in corpus_raw:\n","  temp = \"\"\n","  for c in a:\n","    if not c in punc:\n","      temp += c.lower()\n","  if len(temp) > 0:\n","    corpus.append(temp)\n","\n","print(len(corpus))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["106\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YVSV5rNOaMgn"},"source":["stopw = stopwords.words('english')\n","\n","def stopword_check(phrase):    #returns true if phrase contains no stopwords, false otherwise\n","  phrase = phrase.split(\" \")\n","  for w in phrase:\n","    if w in stopw:\n","      return False\n","  return True\n","  \n","\n","def get_vocab(abstract):\n","  my_words = nltk.word_tokenize(abstract)\n","  my_bigrams = nltk.bigrams(my_words)\n","  my_trigrams = nltk.trigrams(my_words)\n","  words = [(w,) for w in my_words]\n","  bigrams = [b for b in my_bigrams]\n","  trigrams = [t for t in my_trigrams]\n","  vocab = words + bigrams + trigrams\n","  vocab = set(vocab)                       #list of tuples\n","  vocab = [list(v) for v in vocab]         #list of lists\n","  vocab = [\" \".join(v) for v in vocab]     #list of strings\n","  vocab_cleaned = []\n","  for v in vocab:\n","    if stopword_check(v):\n","      vocab_cleaned.append(v)\n","  return vocab_cleaned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZCKS0a7bgw-"},"source":["def take_best(scores, n):\n","  a = sorted(scores, key=scores.get, reverse=True)[:n]\n","  return [(b, scores[b]) for b in a]\n","\n","#tf-idf\n","tfidf = []\n","for abstract in corpus:\n","  scores = dict()\n","  vocab = get_vocab(abstract)\n","  for v in vocab:\n","    term_count = abstract.count(v)\n","    doc_count = 0\n","    for c in corpus:\n","      if v in c:\n","        doc_count += 1\n","    if doc_count == 0:\n","      doc_count = 1\n","    scores[v] = (term_count/len(abstract.split(\" \"))) * np.log(len(corpus)/doc_count)\n","  tfidf.append(take_best(scores, 5))\n","papers['Tf-idf_Keyphrases'] = tfidf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725},"id":"OM09ZRSPAhwn","executionInfo":{"status":"ok","timestamp":1606967309716,"user_tz":360,"elapsed":70936,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"b7122beb-f358-4773-e35e-be0d6bc77fe6"},"source":["f = open(\"nlp_keywords.txt\", \"r\")\n","manual = f.read().splitlines()[:106]\n","f.close()\n","manual = [m.split(\", \") for m in manual]\n","papers['Manual_Keyphrases'] = manual\n","papers"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Abstract</th>\n","      <th>Arxiv Link</th>\n","      <th>Github Link</th>\n","      <th>ID</th>\n","      <th>Title</th>\n","      <th>Textrank_Keyphrases</th>\n","      <th>Tf-idf_Keyphrases</th>\n","      <th>Manual_Keyphrases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Discourse structures are beneficial for vari...</td>\n","      <td>http://arxiv.org/abs/1812.00176</td>\n","      <td>github.com/irit-melodi/irit-stac</td>\n","      <td>1812.00176</td>\n","      <td>A Deep Sequential Model for Discourse Parsing ...</td>\n","      <td>[(discourse dependency structures, 0.130893405...</td>\n","      <td>[(discourse, 0.16946367923698083), (discourse ...</td>\n","      <td>[discourse structures, deep sequential model, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Learning good representations is of crucial ...</td>\n","      <td>http://arxiv.org/abs/1812.00271</td>\n","      <td>github.com/mravanelli/SincNet/</td>\n","      <td>1812.00271</td>\n","      <td>Learning Speaker Representations with Mutual I...</td>\n","      <td>[(useful speaker representations, 0.0751563194...</td>\n","      <td>[(mutual information, 0.07248869058205286), (m...</td>\n","      <td>[sincnet architecture, mutual information, hig...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The explosive growth in fake news and its er...</td>\n","      <td>http://arxiv.org/abs/1812.00315</td>\n","      <td>github.com/borisveytsman/acmart/issues/138</td>\n","      <td>1812.00315</td>\n","      <td>Fake News: A Survey of Research, Detection Met...</td>\n","      <td>[(current fake news research, 0.16925477623337...</td>\n","      <td>[(fake news, 0.236123498436054), (fake, 0.2361...</td>\n","      <td>[fake news, interdisciplinary research, propag...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The amount of dialogue history to include in...</td>\n","      <td>http://arxiv.org/abs/1812.00350</td>\n","      <td>github.com/keras-team/keras</td>\n","      <td>1812.00350</td>\n","      <td>A Study on Dialogue Reward Prediction for Open...</td>\n","      <td>[(dialogue reward predictors, 0.15061766476375...</td>\n","      <td>[(dialogue, 0.13620311544911662), (dialogue re...</td>\n","      <td>[dialogue history, conversational agent, optim...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Detecting controversy in general web pages i...</td>\n","      <td>http://arxiv.org/abs/1812.00382</td>\n","      <td>github.com/aboSamoor/polyglot</td>\n","      <td>1812.00382</td>\n","      <td>Improved and Robust Controversy Detection in G...</td>\n","      <td>[(cross - domain performance, 0.10065964960247...</td>\n","      <td>[(controversy, 0.1589808782083659), (general w...</td>\n","      <td>[detecting controversy, problematic content, n...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>We propose the first joint model for Vietnam...</td>\n","      <td>http://arxiv.org/abs/1812.11459</td>\n","      <td>github.com/acl-org/acl-pub/issues/2</td>\n","      <td>1812.11459</td>\n","      <td>A neural joint model for Vietnamese word segme...</td>\n","      <td>[(joint model obtains state, 0.164290755490313...</td>\n","      <td>[(vietnamese, 0.15289964242990384), (tagging, ...</td>\n","      <td>[joint model, vietnamese, word segmentation, v...</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>This paper proposes a variational self-atten...</td>\n","      <td>http://arxiv.org/abs/1812.11559</td>\n","      <td>github.com/FakeNewsChallenge/fnc-1</td>\n","      <td>1812.11559</td>\n","      <td>Variational Self-attention Model for Sentence ...</td>\n","      <td>[(multi - modal attention distributions, 0.236...</td>\n","      <td>[(vsam, 0.15206866611235), (self-attention, 0....</td>\n","      <td>[self-attention, variational inference, attent...</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>While the volume of scholarly publications h...</td>\n","      <td>http://arxiv.org/abs/1812.11709</td>\n","      <td>github.com/GraphEmbedding/HRLHG\\label{foot:web</td>\n","      <td>1812.11709</td>\n","      <td>Cross-language Citation Recommendation via Hie...</td>\n","      <td>[(cross - language citation recommendation tas...</td>\n","      <td>[(publication, 0.08314747462936381), (cross-la...</td>\n","      <td>[useful candidate papers, foreign language rep...</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>The correct interpretation of quantifier sta...</td>\n","      <td>http://arxiv.org/abs/1812.11737</td>\n","      <td>github.com/goodfeli/dlbook_notation.</td>\n","      <td>1812.11737</td>\n","      <td>The meaning of \"most\" for visual question answ...</td>\n","      <td>[(visual question answering model, 0.173924005...</td>\n","      <td>[(scene, 0.08555584333065498), (visual questio...</td>\n","      <td>[quantifier statements, inference mechanisms, ...</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>We extend our previous work on constituency ...</td>\n","      <td>http://arxiv.org/abs/1812.11760</td>\n","      <td>github.com/nikitakit/self-attentive-parser</td>\n","      <td>1812.11760</td>\n","      <td>Multilingual Constituency Parsing with Self-At...</td>\n","      <td>[(peters et al ., 0.18491858132719172), (pre -...</td>\n","      <td>[(pre-training, 0.15077057899565022), (2018, 0...</td>\n","      <td>[constituency parsing, pre-training, bert, elm...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>106 rows × 8 columns</p>\n","</div>"],"text/plain":["                                              Abstract  ...                                  Manual_Keyphrases\n","0      Discourse structures are beneficial for vari...  ...  [discourse structures, deep sequential model, ...\n","1      Learning good representations is of crucial ...  ...  [sincnet architecture, mutual information, hig...\n","2      The explosive growth in fake news and its er...  ...  [fake news, interdisciplinary research, propag...\n","3      The amount of dialogue history to include in...  ...  [dialogue history, conversational agent, optim...\n","4      Detecting controversy in general web pages i...  ...  [detecting controversy, problematic content, n...\n","..                                                 ...  ...                                                ...\n","101    We propose the first joint model for Vietnam...  ...  [joint model, vietnamese, word segmentation, v...\n","102    This paper proposes a variational self-atten...  ...  [self-attention, variational inference, attent...\n","103    While the volume of scholarly publications h...  ...  [useful candidate papers, foreign language rep...\n","104    The correct interpretation of quantifier sta...  ...  [quantifier statements, inference mechanisms, ...\n","105    We extend our previous work on constituency ...  ...  [constituency parsing, pre-training, bert, elm...\n","\n","[106 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqFHFKgTDS4a","executionInfo":{"status":"ok","timestamp":1606967309719,"user_tz":360,"elapsed":70931,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"d09ba4d1-fd48-4403-84e5-998f4c413c00"},"source":["#keyphrase lengths\n","N = 5*106    #total number of keyphrases\n","avglen_manual = sum([len(phrase.split(\" \")) for keywords in papers[\"Manual_Keyphrases\"] for phrase in keywords])/N\n","avglen_textrank = sum([len(phrase[0].split(\" \")) for keywords in papers[\"Textrank_Keyphrases\"] for phrase in keywords])/N\n","avglen_tfidf = sum([len(phrase[0].split(\" \")) for keywords in papers[\"Tf-idf_Keyphrases\"] for phrase in keywords])/N\n","print(\"Average keyphrase lengths:\", avglen_textrank, avglen_tfidf, avglen_manual)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Average keyphrase lengths: 3.1320754716981134 1.3773584905660377 1.9528301886792452\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJTiGB1yKNLK","executionInfo":{"status":"ok","timestamp":1606967312436,"user_tz":360,"elapsed":73640,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"c762e4dd-bd7c-4e4a-8f99-0d2a9e14917d"},"source":["#fuzzy accuracy evaluation\n","!pip install fuzzywuzzy[speedup]\n","from fuzzywuzzy import fuzz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fuzzywuzzy[speedup] in /usr/local/lib/python3.6/dist-packages (0.18.0)\n","Requirement already satisfied: python-levenshtein>=0.12; extra == \"speedup\" in /usr/local/lib/python3.6/dist-packages (from fuzzywuzzy[speedup]) (0.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (50.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QrY2xeoKLshG"},"source":["#helper functions for code cleanliness\n","\n","def get_textrank(i,j):\n","  global papers\n","  return papers['Textrank_Keyphrases'].iloc[i][j][0]\n","\n","def get_tfidf(i,j):\n","  global papers\n","  return papers['Tf-idf_Keyphrases'].iloc[i][j][0]\n","\n","def get_manual(i,j):\n","  global papers\n","  return papers['Manual_Keyphrases'].iloc[i][j]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pu8i9dz3TQ_B"},"source":["def evaluate():\n","  correct_textrank = 0\n","  correct_tfidf = 0\n","  correct_textrank_partial = 0\n","  correct_tfidf_partial = 0\n","  x = 0\n","  for i in range(106):\n","    correct_textrank += max([fuzz.ratio(get_textrank(i,j), get_manual(i,j)) for j in range(5)])\n","    correct_tfidf += max([fuzz.ratio(get_tfidf(i,j), get_manual(i,j)) for j in range(5)])\n","    correct_textrank_partial += max([fuzz.partial_ratio(get_textrank(i,j), get_manual(i,j)) for j in range(5)])\n","    correct_tfidf_partial += max([fuzz.partial_ratio(get_tfidf(i,j), get_manual(i,j)) for j in range(5)])\n","  return [correct_textrank/106, correct_tfidf/106, correct_textrank_partial/106, correct_tfidf_partial/106]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwX31p_zMeI0","executionInfo":{"status":"ok","timestamp":1606967312439,"user_tz":360,"elapsed":73630,"user":{"displayName":"Evan McKinnon","photoUrl":"","userId":"15729169813940064193"}},"outputId":"79ba0001-f9fa-415a-bf27-6ca4b3a0502f"},"source":["evaluate()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[61.528301886792455, 62.990566037735846, 75.06603773584905, 82.83018867924528]"]},"metadata":{"tags":[]},"execution_count":119}]}]}